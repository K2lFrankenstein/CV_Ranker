{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd10323d-6d45-40c2-a878-2f6117db0c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,fitz\n",
    "import pandas as pd\n",
    "import docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8638cefb-0425-45fc-87d8-ac6b06903a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR  = r\"D:\\psudo_desktop\\RANDOM SEARCH\\CV_Ranker\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "010c4893-ca09-45ce-ad92-9fbf596d841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_newlines(serie):\n",
    "    serie = serie.replace('\\n', ' ')\n",
    "    serie = serie.replace('\\\\n', ' ')\n",
    "    serie = serie.replace('  ', ' ')\n",
    "    serie = serie.replace('  ', ' ')\n",
    "    serie = serie.replace('  ', ' ')\n",
    "    serie = serie.replace('  ', ' ')\n",
    "    serie = serie.replace('  ', ' ')\n",
    "    return serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "043f092d-c37d-45d8-bb6f-10337dcb4838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EXTRACT_TEXT_FROM_PDF(filename):\n",
    "   \n",
    "    pdf_file =  fitz.open(filename)\n",
    "    PDFFILEDATALIST = \"\"\n",
    "\n",
    "    for Page_No,page in enumerate(pdf_file):\n",
    "        pymupdf_text = \"\"\n",
    "        pymupdf_text = pymupdf_text + page.get_text()\n",
    "        ddt  = remove_newlines(pymupdf_text)\n",
    "              \n",
    "        PDFFILEDATALIST+=ddt\n",
    "\n",
    "        \n",
    "    return PDFFILEDATALIST\n",
    "    \n",
    "## Include the things that are found in the raw data;dont leave the spaces for any catogeries not mentioned in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6e09ec47-93a7-465e-b6c0-6e228634a782",
   "metadata": {},
   "outputs": [],
   "source": [
    "data0 = EXTRACT_TEXT_FROM_PDF(r\"D:/psudo_desktop/Study/AAA/IUB/JOB/ds/Resume_Ketul_Patel_d.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "df5f0ab1-3797-4658-800c-36ae25c50d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ketul Patel E-mail: ketul.patel3000@gmail.com | Mobile: +1 812-553-2233 | LinkedIn: ketulpatel-av Education: • Masters of Science in Computer Science, (3.8/4) 2022 – 2024 Indiana University Bloomington (Luddy School of Informatics, Computing, and Engineering) o Completed coursework: Signals and Image Processing, Deep Learning Systems, Music Data Minning ,Computer Networks, Computer Vision, Applied Machine Learning, Elements of AI, Applied Algorithms, Software Engineering, and Engineering Cloud Computing. • Bachelor’s Degree in Technology, Information Technology (9.47/10)  2018 – 2022 Institute: Indus University (Indus Institute of Technology and Engineering) Skills: • Programing languages: Python Programming, R Programming, MATLAB, SQL, C++, Java, Selenium, Git • Data Analysis and Machine Learning: Data Scraping, Data Visualization, Exploratory Data Analysis, Extract, Transform, Load (ETL), Web Scraping, Tableau, Power BI, OpenCV, TensorFlow, PyTorch, BigQuery, Statistical Analysis • Database: MySQL, MongoDB, PostgreSQL • Web Development: Django, Flask, REST API, NodeJS, JavaScript, HTML, CSS, Agile, Jira, JSON Work Experience: • Python Developer (Co-op/Full time) - Uniq Data Solution Pvt. Ltd., Iskon, Ahmedabad April 2021– July 2022 o Led, managed and did risk profiling for 3 projects focused on developing data-driven products. o Developed and implemented algorithms for a social media search engine, resulting in a 40% increase in data mining efficiency for digital marketing campaigns. o Implemented automated process platform to extract data from file formats and automating the Tableau dashboard creation, reducing manual labor involved by 65%, and increasing accuracy of data extracted by 90%. • Research Intern - BISAG-N, Infocity, Gandhinagar June 2021 - September 2021 o Conducted a research project on live data of Bombay Stock Exchange utilizing Time Series Analysis o Resulted in improved accuracy of Volatility Analysis and Risk Assessment by 7% and 3% respectively. • Data visualization intern - Multi Infomedia Pvt. Ltd., Ahmedabad May 2020– July 2020 o Performed statistical analysis of sales data, distribution related logistics data and import data to analyze the trends. o Generated Visualizations dashboards to deliver actionable intel gathered from statistical analysis. • Web Development Intern- Multi Infomedia Pvt. Ltd., Ahmedabad May 2019– July 2019 o Re-engineered Company\\'s website from legacy code, updated database to latest products catalogue, created a dynamic page to update the product line or edit an existing product. Projects: • Google Quick-Draw: o Engineered a Convolutional Neural Network (CNN) model to classify sketches within the \"Quick, Draw!\" Google dataset, demonstrating a commendable 70% accuracy in successfully identifying a wide array of objects and concepts. Employed Python programming, TensorFlow framework, and meticulous data preprocessing to construct, train, and evaluate the CNN model\\'s efficacy for the task at hand. • L2 Analytics: o Transformed data management and retrieval, an innovative project integrating MongoDB for efficient database creation, file uploads, and versatile search capabilities. Utilized Tesseract OCR for text extraction and harnessed a spectrum of Python libraries for seamless data processing and selenium for process automation of data extraction. Employed modular architecture to enhance code organization and reusability, marking a significant advancement in data analytics. • End-of-utterance detecting with CV: o Conducted research project on End-of-Utterance detection using multi-modality domains and Hidden Markov Model, showcasing effectiveness and potential for future advancements in social interactive robots and autonomous dialogue systems. • Optical Music Recognition: o Developed an OMR interface to automatically recognize music notes on scanned scores for the purpose of enabling automatic organ playing. • Stereo Correspondence depth: o Executed MRF-based stereo correspondence algorithm with optimized performance, employing loopy belief propagation to estimate accurate disparity maps and MSE as error measure. • Social media Search Engine: o Designed a Social media search engine for digital marketing use-cases which can search different social media and extract data based on the provided keyword. • Stock market prediction web application using Django: o During internship at BISAG-N used BSE stock market data API and formulated an algorithm (ARIMA model) to predict the trend of stock prices. '"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5d70c524-32f1-41bd-8d22-df9a21bf575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def EXTRACT_TABLEDATA_FROM_DOC(filename):\n",
    "    doc = docx.Document(filename)\n",
    "    table_data_list = []\n",
    "\n",
    "    for p in doc.paragraphs:\n",
    "        table_data_list.append(p.text)\n",
    "\n",
    "    for i, table in enumerate(doc.tables, start=1):\n",
    "        for y, row in enumerate(table.rows):\n",
    "            row_data = [cell.text for cell in row.cells]\n",
    "            rowdata =\",\".join(row_data)\n",
    "            table_data_list.append(rowdata)\n",
    "\n",
    "\n",
    "    \n",
    "    return table_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "36589801-db34-4e4c-9033-57847867a9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = EXTRACT_TABLEDATA_FROM_DOC(r\"D:\\psudo_desktop\\Study\\Ketul Patel CV.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf13cb53-cf50-4fad-aa83-5aad23655d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=\"sk-proj-xGFbQ7M2Gpni4sIU4L0dT3BlbkFJUi3XqLrUwbEQ4ifnFKEc\",\n",
    ")\n",
    "\n",
    "\n",
    "# text-embedding-ada-002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cd6c9fa1-e721-45a8-a461-b28d0e0c7245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2162781b-bee9-47bc-add8-f9943cfad23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_text = data0\n",
    "job_description = \" Front End Developer Job Descriptio - We are seeking a talented Front End Developer to join our dynamic team. As a Front End Developer, you will be responsible for creating visually appealing, user-friendly web interfaces that enhance user experience. You will work closely with our design and back-end development teams to translate design mockups and wireframes into interactive web applications using HTML, CSS, and JavaScript. Your role will involve optimizing web applications for maximum speed and scalability, ensuring cross-browser compatibility, and implementing responsive design. You will also collaborate in the development of user interface components and integrate them with back-end services. The ideal candidate should possess a strong understanding of web development best practices, proficiency in front-end frameworks like React or Angular, and experience with version control systems like Git. Strong problem-solving skills, attention to detail, and the ability to work in a fast-paced environment are essential for this role. Join us and contribute to delivering top-notch digital experiences.\"\n",
    "\n",
    "resume_Hilights = {\"hilight\":\"3y experience in ML/experience | M.Tech/education | PyTorch/skill | award/publications | AWS/certification |\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "19b98bca-70e1-4257-ab0b-781f68b84119",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are expert in matching resumes experience & skill keyword with job descriptions keyword\"},\n",
    "            {\"role\": \"user\", \"content\": (\n",
    "                f\"Given the following job description:\\n{job_description}\\n\"\n",
    "                f\"and the CV:\\n{resume_text}\\n\"\n",
    "                \"Provide Just compatibility score out of 100 like Score = <number>\" \n",
    "                f\"and top5 hilight of the CV in JUST 15 WORD only and in format {resume_Hilights}\\n\"\n",
    "            )}\n",
    "        ],\n",
    "        max_tokens=25\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b5da1f78-f34d-4b50-b423-3b6153b82692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9UizZStfhJFyQlEm1K7ZgKxXoTMCx', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='Score = 30\\n\\n', role='assistant', function_call=None, tool_calls=None))], created=1717109817, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=5, prompt_tokens=1163, total_tokens=1168))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3ddaee7f-ab72-43be-85d9-8daab81049a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4e20cd80-7f07-4bda-a46b-fa71d854a268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score = 30\n"
     ]
    }
   ],
   "source": [
    "print(response_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b845adef-1389-4d8c-8468-4194646d8bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "restructure_CV = {\"fullName\",\"contactInfo\",\"education\",\"work experience\", \"projects\",\"skills\",\"others\"},\n",
    "\n",
    "token_l =len(data0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6db7f8ad-1013-4fd2-82c8-0390176e0210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4546"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2e3a90eb-8b33-4e53-a1e4-117d2025b183",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-16k\",\n",
    "        messages=[\n",
    "{\"role\": \"system\", \"content\": \"You are an expert in structuring resumes from raw data \"},\n",
    "            {\"role\": \"user\", \"content\": (\n",
    "                f\"Given following raw data:\\n{data0}\\n can you recreate the resume in this format {restructure_CV}\\n\"\n",
    "            )}\n",
    "        ],\n",
    "        max_tokens=token_l\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3dd7ed03-7fd2-472b-ba90-4e87125605d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message_structured = response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "80f2c422-3db0-4ca5-8052-c4db5f047c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"fullName\": \"Ketul Patel\",\n",
      "  \"contactInfo\": {\n",
      "    \"email\": \"ketul.patel3000@gmail.com\",\n",
      "    \"mobile\": \"+1 812-553-2233\",\n",
      "    \"LinkedIn\": \"ketulpatel-av\"\n",
      "  },\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"degree\": \"Masters of Science in Computer Science\",\n",
      "      \"gpa\": \"3.8/4\",\n",
      "      \"year\": \"2022 – 2024\",\n",
      "      \"university\": \"Indiana University Bloomington (Luddy School of Informatics, Computing, and Engineering)\",\n",
      "      \"courses\": \"Signals and Image Processing, Deep Learning Systems, Music Data Minning, Computer Networks, Computer Vision, Applied Machine Learning, Elements of AI, Applied Algorithms, Software Engineering, and Engineering Cloud Computing\"\n",
      "    },\n",
      "    {\n",
      "      \"degree\": \"Bachelor’s Degree in Technology\",\n",
      "      \"gpa\": \"9.47/10\",\n",
      "      \"year\": \"2018 – 2022\",\n",
      "      \"university\": \"Indus University (Indus Institute of Technology and Engineering)\"\n",
      "    }\n",
      "  ],\n",
      "  \"skills\": [\n",
      "    \"Python Programming\",\n",
      "    \"R Programming\",\n",
      "    \"MATLAB\",\n",
      "    \"SQL\",\n",
      "    \"C++\",\n",
      "    \"Java\",\n",
      "    \"Selenium\",\n",
      "    \"Git\",\n",
      "    \"Data Scraping\",\n",
      "    \"Data Visualization\",\n",
      "    \"Exploratory Data Analysis\",\n",
      "    \"Extract, Transform, Load (ETL)\",\n",
      "    \"Web Scraping\",\n",
      "    \"Tableau\",\n",
      "    \"Power BI\",\n",
      "    \"OpenCV\",\n",
      "    \"TensorFlow\",\n",
      "    \"PyTorch\",\n",
      "    \"BigQuery\",\n",
      "    \"Statistical Analysis\",\n",
      "    \"MySQL\",\n",
      "    \"MongoDB\",\n",
      "    \"PostgreSQL\",\n",
      "    \"Django\",\n",
      "    \"Flask\",\n",
      "    \"REST API\",\n",
      "    \"NodeJS\",\n",
      "    \"JavaScript\",\n",
      "    \"HTML\",\n",
      "    \"CSS\",\n",
      "    \"Agile\",\n",
      "    \"Jira\",\n",
      "    \"JSON\"\n",
      "  ],\n",
      "  \"work experience\": [\n",
      "    {\n",
      "      \"position\": \"Python Developer (Co-op/Full time)\",\n",
      "      \"company\": \"Uniq Data Solution Pvt. Ltd.,\",\n",
      "      \"location\": \"Iskon, Ahmedabad\",\n",
      "      \"dates\": \"April 2021– July 2022\",\n",
      "      \"highlights\": [\n",
      "        \"Led, managed and did risk profiling for 3 projects focused on developing data-driven products.\",\n",
      "        \"Developed and implemented algorithms for a social media search engine, resulting in a 40% increase in data mining efficiency.\",\n",
      "        \"Implemented automated process platform to extract data from file formats and automating the Tableau dashboard creation, reducing manual labor involved by 65%, and increasing accuracy of data extracted by 90%.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"position\": \"Research Intern\",\n",
      "      \"company\": \"BISAG-N\",\n",
      "      \"location\": \"Infocity, Gandhinagar\",\n",
      "      \"dates\": \"June 2021 - September 2021\",\n",
      "      \"highlights\": [\n",
      "        \"Conducted a research project on live data of Bombay Stock Exchange utilizing Time Series Analysis.\",\n",
      "        \"Improved accuracy of Volatility Analysis and Risk Assessment by 7% and 3% respectively.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"position\": \"Data visualization intern\",\n",
      "      \"company\": \"Multi Infomedia Pvt. Ltd.,\",\n",
      "      \"location\": \"Ahmedabad\",\n",
      "      \"dates\": \"May 2020– July 2020\",\n",
      "      \"highlights\": [\n",
      "        \"Performed statistical analysis of sales data, distribution related logistics data, and import data to analyze trends.\",\n",
      "        \"Generated visualization dashboards from statistical analysis to deliver actionable intel.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"position\": \"Web Development Intern\",\n",
      "      \"company\": \"Multi Infomedia Pvt. Ltd.,\",\n",
      "      \"location\": \"Ahmedabad\",\n",
      "      \"dates\": \"May 2019– July 2019\",\n",
      "      \"highlights\": [\n",
      "        \"Re-engineered company's website from legacy code, updated database to latest product catalog, and created dynamic page for product updates and edits.\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"projects\": [\n",
      "    {\n",
      "      \"title\": \"Google Quick-Draw\",\n",
      "      \"description\": \"Engineered a CNN model to classify sketches within the 'Quick, Draw!' Google dataset with 70% accuracy.\",\n",
      "      \"technologies\": \"Python, TensorFlow\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"L2 Analytics\",\n",
      "      \"description\": \"Integrated MongoDB for efficient database creation, file uploads, and versatile search capabilities. Utilized Tesseract OCR for text extraction and employed Python libraries for seamless data processing.\",\n",
      "      \"technologies\": \"Python, MongoDB, Tesseract OCR\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"End-of-utterance detection with CV\",\n",
      "      \"description\": \"Conducted research on end-of-utterance detection using multi-modality domains and Hidden Markov Model.\",\n",
      "      \"technologies\": \"Python, CV, Hidden Markov Model\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Optical Music Recognition\",\n",
      "      \"description\": \"Developed an OMR interface to automatically recognize music notes on scanned scores for enabling automatic organ playing.\",\n",
      "      \"technologies\": \"Python\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Stereo Correspondence depth\",\n",
      "      \"description\": \"Executed MRF-based stereo correspondence algorithm to estimate accurate disparity maps.\",\n",
      "      \"technologies\": \"Python\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Social media Search Engine\",\n",
      "      \"description\": \"Designed a social media search engine for digital marketing use-cases.\",\n",
      "      \"technologies\": \"Python\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Stock market prediction web application using Django\",\n",
      "      \"description\": \"Utilized BSE stock market data API and ARIMA model to predict stock price trends.\",\n",
      "      \"technologies\": \"Python, Django\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Top 5 highlights:\n",
      "1. Led data-driven projects with risk profiling, resulting in increased efficiency and automation.\n",
      "2. Conducted research on live data, improving accuracy of volatility analysis and risk assessment.\n",
      "3. Performed statistical analysis and generated visualizations for actionable business insights.\n",
      "4. Re-engineered website, updated database, and created dynamic product pages.\n",
      "5. Developed models for classification, music recognition, and stereo correspondence, showcasing technical expertise.\n"
     ]
    }
   ],
   "source": [
    "print(response_message_structured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c33dc3b-0380-4fd6-ba8f-8cde04fe6e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "\n",
    "# Convert the string to a Python dictionary\n",
    "data = ast.literal_eval(response_message_structured)\n",
    "\n",
    "# Function to flatten the nested dictionary\n",
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key =  k if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "# Flatten the nested dictionary\n",
    "flattened_data = flatten_dict(data['resume'])\n",
    "\n",
    "# Create a DataFrame from the flattened dictionary\n",
    "df = pd.DataFrame([flattened_data])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "97f7dcc6-3897-478a-a918-d6d8075bd88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': 'Jinal Babariya',\n",
       " 'Phone': '(+91)6354149867',\n",
       " 'Email': 'Jinalbabariya174@gmail.com',\n",
       " 'LinkedIn': 'https://www.linkedin.com/in/jinal-babariya-8aa938220/',\n",
       " 'Programming Language': 'C, Python',\n",
       " 'Scripting Language': 'JavaScript',\n",
       " 'Institute': 'L.J Institute of Engineering and Technology',\n",
       " 'Duration': 'Jan 2022 - Present',\n",
       " 'CGPA': '8.77',\n",
       " 'School': 'Shree Saradar Patel Vidhyalay, Dahida',\n",
       " 'Year': 'March 2016',\n",
       " 'Result': '79.83%',\n",
       " 'Company': 'Brainybeam Technologies (Software Development Training)',\n",
       " 'Responsibilities': ['Core Python', 'Web Framework: Django'],\n",
       " 'PROJECTS': [{'Project Title': 'Cloud Website Template',\n",
       "   'Technologies Used': 'HTML, CSS, JS, Bootstrap, MySQL'}]}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "12d1d334-bde3-4ad0-a5aa-174bcaf6f5b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'resume'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(items)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Flatten the nested dictionary\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m flattened_data \u001b[38;5;241m=\u001b[39m flatten_dict(\u001b[43mresponse_message_structured\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresume\u001b[49m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Create a DataFrame from the flattened dictionary\u001b[39;00m\n\u001b[0;32m     16\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([flattened_data])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'resume'"
     ]
    }
   ],
   "source": [
    "# Function to flatten the nested dictionary\n",
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "# Flatten the nested dictionary\n",
    "flattened_data = flatten_dict(response_message_structured.resume)\n",
    "\n",
    "# Create a DataFrame from the flattened dictionary\n",
    "df = pd.DataFrame([flattened_data])\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855b8434-bc83-436b-8d4e-7f28c5700384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
